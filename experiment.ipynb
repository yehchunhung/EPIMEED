{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105d3ce5-2f26-4b65-84a1-02aa9de2c2af",
   "metadata": {},
   "source": [
    "Tensorflow GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b106b46a-b7a6-4160-aaf6-2d0e57411a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 12:02:33.477614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(devices = [\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\"], cross_device_ops = tf.distribute.HierarchicalCopyAllReduce())\n",
    "\n",
    "with strategy.scope():\n",
    "    x = tf.Variable(1.)\n",
    "    \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a744b7-1301-4428-a408-c11d8eb5233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d4c4be-173f-4516-a613-08a40699ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5817f-1479-47fe-ae70-424374741242",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5bc31f-4810-4735-af8d-42aedbe00876",
   "metadata": {},
   "source": [
    "MEED2 emotion/intent distribution check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b23fa443-be2e-4996-9741-f24ed7dde3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 00:08:08.803043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import random\n",
    "from datasets import *\n",
    "import csv\n",
    "import ast\n",
    "from os.path import join\n",
    "\n",
    "# # create the logging file\n",
    "# logging.basicConfig(filename = \"log/xenbot-os-dramatic-rest-red+_mask_.log\", level = logging.INFO)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba28b43-a804-44b9-829b-9598b97a1ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 16441],\n",
       "       [    1, 30014],\n",
       "       [    2, 23627],\n",
       "       [    3,  3664],\n",
       "       [    4,  7886],\n",
       "       [    5, 43936],\n",
       "       [    6, 54646],\n",
       "       [    7, 13908],\n",
       "       [    8, 11225],\n",
       "       [    9, 19436],\n",
       "       [   10, 27694],\n",
       "       [   11, 18776],\n",
       "       [   12,  9406],\n",
       "       [   13, 14791],\n",
       "       [   14,  3683],\n",
       "       [   15, 26167],\n",
       "       [   16, 10487],\n",
       "       [   17, 15207],\n",
       "       [   18, 11427],\n",
       "       [   19, 23463],\n",
       "       [   20,  8147],\n",
       "       [   21, 20527],\n",
       "       [   22,  7862],\n",
       "       [   23, 61770],\n",
       "       [   24,  9171],\n",
       "       [   25,  5102],\n",
       "       [   26,  9157],\n",
       "       [   27, 67943],\n",
       "       [   28, 12794],\n",
       "       [   29, 12837],\n",
       "       [   30, 15401],\n",
       "       [   31, 29117],\n",
       "       [   32, 51166],\n",
       "       [   33, 33866],\n",
       "       [   34, 10056],\n",
       "       [   35, 19832],\n",
       "       [   36, 27533],\n",
       "       [   37, 28282],\n",
       "       [   38, 85438],\n",
       "       [   39, 24639],\n",
       "       [   40, 46876]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the emotion label\n",
    "temp = np.load('datasets/red+/train/uttr_emots.npy')\n",
    "\n",
    "np.array(np.unique(temp, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9886d877-8ebd-4195-89e2-9515265a43cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38    44063\n",
       "32     8447\n",
       "33     8117\n",
       "40     4277\n",
       "39     2369\n",
       "36     2320\n",
       "5       865\n",
       "17      704\n",
       "23      412\n",
       "27      269\n",
       "12      251\n",
       "2       243\n",
       "15      227\n",
       "6       152\n",
       "34      136\n",
       "7        82\n",
       "35       72\n",
       "1        68\n",
       "0        62\n",
       "28       58\n",
       "21       55\n",
       "31       54\n",
       "20       53\n",
       "9        50\n",
       "26       45\n",
       "24       35\n",
       "37       29\n",
       "18       21\n",
       "10       19\n",
       "19       17\n",
       "8        13\n",
       "30        8\n",
       "4         8\n",
       "11        7\n",
       "25        7\n",
       "13        6\n",
       "3         3\n",
       "22        2\n",
       "16        2\n",
       "29        1\n",
       "Name: meed2, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 3 (lowest)\n",
    "temp = pd.read_csv('emotions/model-red+/meed2+/red+_test_int.csv')\n",
    "\n",
    "temp['meed2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eba61cf-ff17-46bd-bc5d-bc5eb84985e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38    44063\n",
       "32     8446\n",
       "33     8116\n",
       "40     4277\n",
       "39     2369\n",
       "36     2320\n",
       "5       866\n",
       "17      704\n",
       "23      412\n",
       "27      270\n",
       "12      251\n",
       "2       243\n",
       "15      227\n",
       "6       152\n",
       "34      136\n",
       "7        82\n",
       "35       72\n",
       "1        68\n",
       "0        62\n",
       "28       58\n",
       "21       55\n",
       "31       54\n",
       "20       53\n",
       "9        50\n",
       "26       45\n",
       "24       35\n",
       "37       29\n",
       "18       21\n",
       "10       19\n",
       "19       17\n",
       "8        13\n",
       "30        8\n",
       "4         8\n",
       "11        7\n",
       "25        7\n",
       "13        6\n",
       "3         3\n",
       "22        2\n",
       "16        2\n",
       "29        1\n",
       "Name: meed2, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('emotions/model-red+/meed2+/red+_mask_test_int.csv')\n",
    "\n",
    "temp['meed2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3043c5-20d1-4111-9566-d30a32920d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>tar_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--&gt; disappointed I actually made good friends,...</td>\n",
       "      <td>sympathizing I’m sorry you’re going through th...</td>\n",
       "      <td>questioning What would you have to do to take ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--&gt; embarrassed This is one of those typical g...</td>\n",
       "      <td>sympathizing I’m so sorry you’re going through...</td>\n",
       "      <td>neutral nah, you're awesome. although it may s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--&gt; furious Seriously. You blocked your ex for...</td>\n",
       "      <td>sympathizing I’m so sorry you’re going through...</td>\n",
       "      <td>acknowledging Sounds to me like you just remem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--&gt; trusting Just a note, I'm posting this for...</td>\n",
       "      <td>sympathizing I’m so sorry you’re going through...</td>\n",
       "      <td>suggesting you should tell them to post on red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--&gt; faithful I just feel like we never win. Sc...</td>\n",
       "      <td>wishing Good luck!</td>\n",
       "      <td>suggesting &lt;URL&gt;  What's up with that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>--&gt; annoyed Would anyone on here actually care...</td>\n",
       "      <td>sympathizing I’m here if you need someone to t...</td>\n",
       "      <td>questioning I don’t really know how to help bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>--&gt; suggesting I want to disappear and heal an...</td>\n",
       "      <td>apprehensive /&lt;SUBREDDIT&gt;</td>\n",
       "      <td>questioning Have you looked into yoga retreats?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>--&gt; anxious This has been happening a lot rece...</td>\n",
       "      <td>questioning Have you talked to your doctor abo...</td>\n",
       "      <td>anxious Whenever I get this panic feeling I ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>--&gt; suggesting Maybe I should just be dead. Ma...</td>\n",
       "      <td>suggesting Maybe I should just be dead. Maybe ...</td>\n",
       "      <td>apprehensive You need to work on your mindset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>--&gt; joyful Hey everyone. I made a website that...</td>\n",
       "      <td>annoyed &lt;URL&gt;  &lt;URL&gt;</td>\n",
       "      <td>wishing Thank you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    --> disappointed I actually made good friends,...   \n",
       "1    --> embarrassed This is one of those typical g...   \n",
       "2    --> furious Seriously. You blocked your ex for...   \n",
       "3    --> trusting Just a note, I'm posting this for...   \n",
       "4    --> faithful I just feel like we never win. Sc...   \n",
       "..                                                 ...   \n",
       "495  --> annoyed Would anyone on here actually care...   \n",
       "496  --> suggesting I want to disappear and heal an...   \n",
       "497  --> anxious This has been happening a lot rece...   \n",
       "498  --> suggesting Maybe I should just be dead. Ma...   \n",
       "499  --> joyful Hey everyone. I made a website that...   \n",
       "\n",
       "                                                pred_y  \\\n",
       "0    sympathizing I’m sorry you’re going through th...   \n",
       "1    sympathizing I’m so sorry you’re going through...   \n",
       "2    sympathizing I’m so sorry you’re going through...   \n",
       "3    sympathizing I’m so sorry you’re going through...   \n",
       "4                                   wishing Good luck!   \n",
       "..                                                 ...   \n",
       "495  sympathizing I’m here if you need someone to t...   \n",
       "496                          apprehensive /<SUBREDDIT>   \n",
       "497  questioning Have you talked to your doctor abo...   \n",
       "498  suggesting Maybe I should just be dead. Maybe ...   \n",
       "499                               annoyed <URL>  <URL>   \n",
       "\n",
       "                                                 tar_y  \n",
       "0    questioning What would you have to do to take ...  \n",
       "1    neutral nah, you're awesome. although it may s...  \n",
       "2    acknowledging Sounds to me like you just remem...  \n",
       "3    suggesting you should tell them to post on red...  \n",
       "4               suggesting <URL>  What's up with that?  \n",
       "..                                                 ...  \n",
       "495  questioning I don’t really know how to help bu...  \n",
       "496    questioning Have you looked into yoga retreats?  \n",
       "497  anxious Whenever I get this panic feeling I ju...  \n",
       "498  apprehensive You need to work on your mindset ...  \n",
       "499                                  wishing Thank you  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_plain = pd.read_csv('prediction-listener/red/plain/plain-os-dramatic-rest-red-plain.csv')\n",
    "\n",
    "red_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85551c8d-3b9e-401c-992c-0be2800b3b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sympathizing I’m sorry you’re going through this. If you need someone to talk to, feel free to message me.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = red_plain.iloc[0, :]\n",
    "\n",
    "temp['pred_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c7a573c-5ece-4abb-a1f7-42cb8af68966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' hopeful I really hope I can do this! I can at least try!\\n',\n",
       " ' confident Go crush it!\\n',\n",
       " \" hopeful I did it!!!!! The manager said she'd call me back within the week!! Thank you for the support!\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['context'].split('-->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8278656-d324-4da6-aad5-0ac01fd2ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_context_emotion(context):\n",
    "    context_uttr_list = context.split('-->')\n",
    "    emotion_list = []\n",
    "    refined_uttr_list = []\n",
    "\n",
    "    for uttr in context_uttr_list[1:]:\n",
    "        emotion = uttr.split()[0]\n",
    "        refined_uttr = ' '.join(uttr.split()[1:])\n",
    "        emotion_list.append(emotion)\n",
    "        refined_uttr_list.append(refined_uttr)\n",
    "    \n",
    "    return emotion_list, refined_uttr_list\n",
    "\n",
    "def extract_pred_emotion(pred):\n",
    "    emotion = pred.split()[0]\n",
    "    uttr = ' '.join(pred.split()[1:])\n",
    "    \n",
    "    return emotion, uttr\n",
    "\n",
    "def extract_tar_emotion(tar):\n",
    "    emotion = tar.split()[0]\n",
    "    uttr = ' '.join(tar.split()[1:])\n",
    "    \n",
    "    return emotion, uttr\n",
    "\n",
    "def build_emotion_df(df):\n",
    "    context_emotion_col = []\n",
    "    context_col = []\n",
    "    pred_emotion_col, tar_emotion_col = [], []\n",
    "    pred_y_col, tar_y_col = [], []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        context_emotion, context = extract_context_emotion(row['context'])\n",
    "        pred_emotion, pred_y = extract_pred_emotion(row['pred_y'])\n",
    "        tar_emotion, tar_y = extract_tar_emotion(row['tar_y'])\n",
    "        \n",
    "        context_emotion_col.append(context_emotion)\n",
    "        context_col.append(context)\n",
    "        pred_emotion_col.append(pred_emotion)\n",
    "        pred_y_col.append(pred_y)\n",
    "        tar_emotion_col.append(tar_emotion)\n",
    "        tar_y_col.append(tar_y)\n",
    "    \n",
    "    return pd.DataFrame({'emotion': context_emotion_col, 'context': context_col, \n",
    "                         'pred_emotion': pred_emotion_col, 'pred_y': pred_y_col, \n",
    "                         'tar_emotion': tar_emotion_col, 'tar_y': tar_y_col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3b60094-84ad-4abe-920f-84331ce14f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>context</th>\n",
       "      <th>pred_emotion</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>tar_emotion</th>\n",
       "      <th>tar_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[disappointed]</td>\n",
       "      <td>[I actually made good friends, hung out with p...</td>\n",
       "      <td>sympathizing</td>\n",
       "      <td>I’m sorry you’re going through this. If you ne...</td>\n",
       "      <td>questioning</td>\n",
       "      <td>What would you have to do to take a year off a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[embarrassed]</td>\n",
       "      <td>[This is one of those typical girl stories, wh...</td>\n",
       "      <td>sympathizing</td>\n",
       "      <td>I’m so sorry you’re going through this. I hope...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>nah, you're awesome. although it may seem a bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[furious]</td>\n",
       "      <td>[Seriously. You blocked your ex for a reason. ...</td>\n",
       "      <td>sympathizing</td>\n",
       "      <td>I’m so sorry you’re going through this.</td>\n",
       "      <td>acknowledging</td>\n",
       "      <td>Sounds to me like you just remembered why you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[trusting]</td>\n",
       "      <td>[Just a note, I'm posting this for a friend wh...</td>\n",
       "      <td>sympathizing</td>\n",
       "      <td>I’m so sorry you’re going through this. I hope...</td>\n",
       "      <td>suggesting</td>\n",
       "      <td>you should tell them to post on reddit rather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[faithful]</td>\n",
       "      <td>[I just feel like we never win. Screw the mach...</td>\n",
       "      <td>wishing</td>\n",
       "      <td>Good luck!</td>\n",
       "      <td>suggesting</td>\n",
       "      <td>&lt;URL&gt; What's up with that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[annoyed]</td>\n",
       "      <td>[Would anyone on here actually care if there i...</td>\n",
       "      <td>sympathizing</td>\n",
       "      <td>I’m here if you need someone to talk to.</td>\n",
       "      <td>questioning</td>\n",
       "      <td>I don’t really know how to help but, wanna talk?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>[suggesting]</td>\n",
       "      <td>[I want to disappear and heal and move on from...</td>\n",
       "      <td>apprehensive</td>\n",
       "      <td>/&lt;SUBREDDIT&gt;</td>\n",
       "      <td>questioning</td>\n",
       "      <td>Have you looked into yoga retreats?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>[anxious]</td>\n",
       "      <td>[This has been happening a lot recently, but I...</td>\n",
       "      <td>questioning</td>\n",
       "      <td>Have you talked to your doctor about this?</td>\n",
       "      <td>anxious</td>\n",
       "      <td>Whenever I get this panic feeling I just pick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[suggesting]</td>\n",
       "      <td>[Maybe I should just be dead. Maybe I’ll be ha...</td>\n",
       "      <td>suggesting</td>\n",
       "      <td>Maybe I should just be dead. Maybe I’ll be hap...</td>\n",
       "      <td>apprehensive</td>\n",
       "      <td>You need to work on your mindset first. Are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>[joyful]</td>\n",
       "      <td>[Hey everyone. I made a website that has puzzl...</td>\n",
       "      <td>annoyed</td>\n",
       "      <td>&lt;URL&gt; &lt;URL&gt;</td>\n",
       "      <td>wishing</td>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            emotion                                            context  \\\n",
       "0    [disappointed]  [I actually made good friends, hung out with p...   \n",
       "1     [embarrassed]  [This is one of those typical girl stories, wh...   \n",
       "2         [furious]  [Seriously. You blocked your ex for a reason. ...   \n",
       "3        [trusting]  [Just a note, I'm posting this for a friend wh...   \n",
       "4        [faithful]  [I just feel like we never win. Screw the mach...   \n",
       "..              ...                                                ...   \n",
       "495       [annoyed]  [Would anyone on here actually care if there i...   \n",
       "496    [suggesting]  [I want to disappear and heal and move on from...   \n",
       "497       [anxious]  [This has been happening a lot recently, but I...   \n",
       "498    [suggesting]  [Maybe I should just be dead. Maybe I’ll be ha...   \n",
       "499        [joyful]  [Hey everyone. I made a website that has puzzl...   \n",
       "\n",
       "     pred_emotion                                             pred_y  \\\n",
       "0    sympathizing  I’m sorry you’re going through this. If you ne...   \n",
       "1    sympathizing  I’m so sorry you’re going through this. I hope...   \n",
       "2    sympathizing            I’m so sorry you’re going through this.   \n",
       "3    sympathizing  I’m so sorry you’re going through this. I hope...   \n",
       "4         wishing                                         Good luck!   \n",
       "..            ...                                                ...   \n",
       "495  sympathizing           I’m here if you need someone to talk to.   \n",
       "496  apprehensive                                       /<SUBREDDIT>   \n",
       "497   questioning         Have you talked to your doctor about this?   \n",
       "498    suggesting  Maybe I should just be dead. Maybe I’ll be hap...   \n",
       "499       annoyed                                        <URL> <URL>   \n",
       "\n",
       "       tar_emotion                                              tar_y  \n",
       "0      questioning  What would you have to do to take a year off a...  \n",
       "1          neutral  nah, you're awesome. although it may seem a bu...  \n",
       "2    acknowledging  Sounds to me like you just remembered why you ...  \n",
       "3       suggesting  you should tell them to post on reddit rather ...  \n",
       "4       suggesting                         <URL> What's up with that?  \n",
       "..             ...                                                ...  \n",
       "495    questioning   I don’t really know how to help but, wanna talk?  \n",
       "496    questioning                Have you looked into yoga retreats?  \n",
       "497        anxious  Whenever I get this panic feeling I just pick ...  \n",
       "498   apprehensive  You need to work on your mindset first. Are th...  \n",
       "499        wishing                                          Thank you  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_emotion_df(red_plain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c794d-8d54-41d7-9c7e-3122a315138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 2\n",
    "red_test = pd.read_csv('emotions/model-red/meed2/red+_test_int.csv')\n",
    "red_test['meed2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bfabf0-a5ec-49a8-90b7-53f2c32a63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_test['ground'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca80cf-91aa-4759-aa7a-1f4c7a1bb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/red+_mask/test/encoded.txt') as infile:\n",
    "    lines = infile.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        print(line.split('\\t')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc53aef-3257-46ae-bc81-765508cf2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_indices, listener_indices = [], []\n",
    "input_line_indices = []\n",
    "\n",
    "with open('datasets/red+_mask/test/encoded.txt') as infile:\n",
    "    lines = infile.readlines()\n",
    "    line_index = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        line_lst = line.split('\\t')\n",
    "        if len(line_lst) < 5:\n",
    "            print(line)\n",
    "            print(line_index)\n",
    "            \n",
    "        start_ind, end_ind = int(line_lst[-1].split(',')[0]), int(line_lst[-1].split(',')[1])\n",
    "\n",
    "        if (start_ind + end_ind) % 2 == 1:\n",
    "            speaker_indices.append(start_ind)\n",
    "            listener_indices.append(end_ind)\n",
    "            input_line_indices.append(line_index)\n",
    "\n",
    "        line_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e107a0-42a2-4909-ba61-76e8840726da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71,\n",
       " 198,\n",
       " 240,\n",
       " 241,\n",
       " 395,\n",
       " 494,\n",
       " 524,\n",
       " 727,\n",
       " 729,\n",
       " 897,\n",
       " 1040,\n",
       " 1208,\n",
       " 1501,\n",
       " 1592,\n",
       " 1752,\n",
       " 1776,\n",
       " 2042,\n",
       " 2236,\n",
       " 2717,\n",
       " 2753,\n",
       " 2834,\n",
       " 2920,\n",
       " 2996,\n",
       " 3076,\n",
       " 3454,\n",
       " 3544,\n",
       " 3643,\n",
       " 3710,\n",
       " 3809,\n",
       " 3873,\n",
       " 3955,\n",
       " 4085,\n",
       " 4092,\n",
       " 4472,\n",
       " 4841,\n",
       " 4949,\n",
       " 4960,\n",
       " 5091,\n",
       " 5179,\n",
       " 5180,\n",
       " 5295,\n",
       " 5392,\n",
       " 5639,\n",
       " 5679,\n",
       " 5738,\n",
       " 5783,\n",
       " 5910,\n",
       " 6292,\n",
       " 6593,\n",
       " 6718,\n",
       " 7215,\n",
       " 7237,\n",
       " 7248,\n",
       " 7429,\n",
       " 7457,\n",
       " 7822,\n",
       " 7943,\n",
       " 7956,\n",
       " 8019,\n",
       " 8086,\n",
       " 8170,\n",
       " 8234,\n",
       " 8246,\n",
       " 8343,\n",
       " 8356,\n",
       " 8545,\n",
       " 8551,\n",
       " 8616,\n",
       " 8908,\n",
       " 8985,\n",
       " 9232,\n",
       " 9271,\n",
       " 9292,\n",
       " 9500,\n",
       " 9520,\n",
       " 9524,\n",
       " 9647,\n",
       " 9804,\n",
       " 9829,\n",
       " 10157,\n",
       " 10297,\n",
       " 10319,\n",
       " 10355,\n",
       " 10394,\n",
       " 10610,\n",
       " 10698,\n",
       " 10808,\n",
       " 10896,\n",
       " 10916,\n",
       " 10945,\n",
       " 11037,\n",
       " 11214,\n",
       " 11316,\n",
       " 11567,\n",
       " 11691,\n",
       " 11840,\n",
       " 11846,\n",
       " 11866,\n",
       " 11930,\n",
       " 12087,\n",
       " 12620,\n",
       " 13224,\n",
       " 13787,\n",
       " 13816,\n",
       " 13998,\n",
       " 14088,\n",
       " 14211,\n",
       " 14321,\n",
       " 14582,\n",
       " 14716,\n",
       " 14719,\n",
       " 14744,\n",
       " 14768,\n",
       " 14882,\n",
       " 14967,\n",
       " 15062,\n",
       " 15125,\n",
       " 15144,\n",
       " 15252,\n",
       " 15327,\n",
       " 15575,\n",
       " 15684,\n",
       " 15693,\n",
       " 15978,\n",
       " 15992,\n",
       " 16167,\n",
       " 16176,\n",
       " 16302,\n",
       " 16577,\n",
       " 16600,\n",
       " 16664,\n",
       " 16674,\n",
       " 16773,\n",
       " 16861,\n",
       " 16921,\n",
       " 16924,\n",
       " 16934,\n",
       " 17054,\n",
       " 17225,\n",
       " 17495,\n",
       " 17555,\n",
       " 17907,\n",
       " 18216,\n",
       " 18330,\n",
       " 18434,\n",
       " 18732,\n",
       " 18749,\n",
       " 18901,\n",
       " 19523,\n",
       " 19557,\n",
       " 19572,\n",
       " 19865,\n",
       " 19884,\n",
       " 20016,\n",
       " 20042,\n",
       " 20071,\n",
       " 20099,\n",
       " 20195,\n",
       " 20205,\n",
       " 20279,\n",
       " 20460,\n",
       " 20673,\n",
       " 20799,\n",
       " 20841,\n",
       " 20863,\n",
       " 20908,\n",
       " 21017,\n",
       " 21168,\n",
       " 21579,\n",
       " 21713,\n",
       " 22044,\n",
       " 22066,\n",
       " 22190,\n",
       " 22357,\n",
       " 22382,\n",
       " 22494,\n",
       " 22501,\n",
       " 22625,\n",
       " 22733,\n",
       " 22790,\n",
       " 23124,\n",
       " 23351,\n",
       " 23475,\n",
       " 23607,\n",
       " 23772,\n",
       " 23991,\n",
       " 24097,\n",
       " 24545,\n",
       " 24556,\n",
       " 24898,\n",
       " 25078,\n",
       " 25121,\n",
       " 25548,\n",
       " 25852,\n",
       " 26056,\n",
       " 26503,\n",
       " 26526,\n",
       " 26572,\n",
       " 27141,\n",
       " 27199,\n",
       " 27446,\n",
       " 27631,\n",
       " 27653,\n",
       " 27675,\n",
       " 27728,\n",
       " 27844,\n",
       " 27991,\n",
       " 28070,\n",
       " 28442,\n",
       " 28462,\n",
       " 28585,\n",
       " 28691,\n",
       " 28753,\n",
       " 28828,\n",
       " 28871,\n",
       " 28989,\n",
       " 29133,\n",
       " 29324,\n",
       " 29507,\n",
       " 29698,\n",
       " 29878,\n",
       " 29969,\n",
       " 29972,\n",
       " 30059,\n",
       " 30107,\n",
       " 30166,\n",
       " 30426,\n",
       " 30547,\n",
       " 30569,\n",
       " 30732,\n",
       " 30736,\n",
       " 30824,\n",
       " 30863,\n",
       " 30866,\n",
       " 30924,\n",
       " 30940,\n",
       " 31204,\n",
       " 31216,\n",
       " 31295,\n",
       " 31483,\n",
       " 31659,\n",
       " 31750,\n",
       " 31897,\n",
       " 31970,\n",
       " 32247,\n",
       " 32467,\n",
       " 32542,\n",
       " 32683,\n",
       " 32690,\n",
       " 32789,\n",
       " 32980,\n",
       " 32991,\n",
       " 33110,\n",
       " 33187,\n",
       " 33205,\n",
       " 33293,\n",
       " 33700,\n",
       " 33834,\n",
       " 34031,\n",
       " 34297,\n",
       " 34300,\n",
       " 34423,\n",
       " 34434,\n",
       " 34453,\n",
       " 34828,\n",
       " 35140,\n",
       " 35145,\n",
       " 35149,\n",
       " 35255,\n",
       " 35500,\n",
       " 35544,\n",
       " 35580,\n",
       " 35732,\n",
       " 35734,\n",
       " 35929,\n",
       " 36057,\n",
       " 36309,\n",
       " 36403,\n",
       " 36451,\n",
       " 37008,\n",
       " 37014,\n",
       " 37136,\n",
       " 37197,\n",
       " 37216,\n",
       " 37337,\n",
       " 37404,\n",
       " 38365,\n",
       " 38542,\n",
       " 38979,\n",
       " 39033,\n",
       " 39044,\n",
       " 39086,\n",
       " 39127,\n",
       " 39161,\n",
       " 39166,\n",
       " 39182,\n",
       " 39218,\n",
       " 39519,\n",
       " 39546,\n",
       " 39586,\n",
       " 39648,\n",
       " 39898,\n",
       " 39908,\n",
       " 39915,\n",
       " 39917,\n",
       " 40445,\n",
       " 40543,\n",
       " 40573,\n",
       " 40752,\n",
       " 40882,\n",
       " 40962,\n",
       " 41397,\n",
       " 41416,\n",
       " 41583,\n",
       " 41775,\n",
       " 41914,\n",
       " 41951,\n",
       " 42063,\n",
       " 42208,\n",
       " 42275,\n",
       " 42383,\n",
       " 42535,\n",
       " 42579,\n",
       " 42595,\n",
       " 42675,\n",
       " 42873,\n",
       " 43131,\n",
       " 43183,\n",
       " 43294,\n",
       " 43610,\n",
       " 44106,\n",
       " 44163,\n",
       " 44174,\n",
       " 44564,\n",
       " 44634,\n",
       " 45053,\n",
       " 45059,\n",
       " 45424,\n",
       " 45603,\n",
       " 46154,\n",
       " 46377,\n",
       " 46431,\n",
       " 46583,\n",
       " 46636,\n",
       " 46637,\n",
       " 46792,\n",
       " 46859,\n",
       " 46863,\n",
       " 47390,\n",
       " 47565,\n",
       " 47757,\n",
       " 47988,\n",
       " 48145,\n",
       " 48186,\n",
       " 48267,\n",
       " 48307,\n",
       " 48370,\n",
       " 48837,\n",
       " 48882,\n",
       " 48902,\n",
       " 48905,\n",
       " 48913,\n",
       " 49096,\n",
       " 49428,\n",
       " 49439,\n",
       " 49868,\n",
       " 49891,\n",
       " 49959,\n",
       " 50081,\n",
       " 50240,\n",
       " 50463,\n",
       " 50827,\n",
       " 51322,\n",
       " 51496,\n",
       " 51668,\n",
       " 51847,\n",
       " 52171,\n",
       " 52193,\n",
       " 52277,\n",
       " 52315,\n",
       " 52544,\n",
       " 52549,\n",
       " 52783,\n",
       " 52965,\n",
       " 52984,\n",
       " 53023,\n",
       " 53090,\n",
       " 53140,\n",
       " 53242,\n",
       " 53384,\n",
       " 53429,\n",
       " 53457,\n",
       " 53632,\n",
       " 53713,\n",
       " 53796,\n",
       " 53822,\n",
       " 54118,\n",
       " 54240,\n",
       " 54338,\n",
       " 54499,\n",
       " 54628,\n",
       " 54841,\n",
       " 54989,\n",
       " 55044,\n",
       " 55208,\n",
       " 55417,\n",
       " 56024,\n",
       " 56043,\n",
       " 56105,\n",
       " 56293,\n",
       " 56888,\n",
       " 56908,\n",
       " 56929,\n",
       " 57258,\n",
       " 57372,\n",
       " 57448,\n",
       " 57497,\n",
       " 57567,\n",
       " 57856,\n",
       " 57910,\n",
       " 58002,\n",
       " 58060,\n",
       " 58063,\n",
       " 58067,\n",
       " 58270,\n",
       " 58413,\n",
       " 58482,\n",
       " 59269,\n",
       " 59402,\n",
       " 59661,\n",
       " 60170,\n",
       " 60404,\n",
       " 60643,\n",
       " 60689,\n",
       " 60698,\n",
       " 60885,\n",
       " 61057,\n",
       " 61110,\n",
       " 61175,\n",
       " 61195,\n",
       " 61200,\n",
       " 61458,\n",
       " 61877,\n",
       " 61881,\n",
       " 62092,\n",
       " 62093,\n",
       " 62470,\n",
       " 62576,\n",
       " 62705,\n",
       " 62922,\n",
       " 63307,\n",
       " 63409,\n",
       " 63440,\n",
       " 63723,\n",
       " 63743,\n",
       " 64011,\n",
       " 64163,\n",
       " 64197,\n",
       " 64210,\n",
       " 64265,\n",
       " 64335,\n",
       " 64746,\n",
       " 64840,\n",
       " 65192,\n",
       " 65851,\n",
       " 66259,\n",
       " 66368,\n",
       " 66369,\n",
       " 66511,\n",
       " 66761,\n",
       " 66943,\n",
       " 67124,\n",
       " 67582,\n",
       " 67823,\n",
       " 68452,\n",
       " 68644,\n",
       " 69926,\n",
       " 70223,\n",
       " 71017,\n",
       " 71085,\n",
       " 71093,\n",
       " 71184,\n",
       " 71249,\n",
       " 71458,\n",
       " 71540,\n",
       " 71560,\n",
       " 71949,\n",
       " 72117,\n",
       " 72150,\n",
       " 72232,\n",
       " 72426,\n",
       " 72550,\n",
       " 72640,\n",
       " 72647,\n",
       " 72787,\n",
       " 72802,\n",
       " 73346,\n",
       " 73437,\n",
       " 73474,\n",
       " 73481]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices = random.sample(input_line_indices, 500)\n",
    "test_indices.sort()\n",
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc753dc8-4b44-46af-9547-5337a88b7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load('prediction-listener/red+_mask.npy')[127]\n",
    "\n",
    "np.save('prediction-listener/red+_mask_16302.npy', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42905d6-e580-49c5-9671-55f3748706aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prediction-listener/red+_mask.npy', test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f5dd1-685b-4a41-8750-cb4720b0f414",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da549d-b940-4dc1-a245-d286212884fc",
   "metadata": {},
   "source": [
    "Merge the training dataframe with the annotated rationale masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a23ddef-3330-4eca-8b03-e576083ce863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3169: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "train_output = pd.read_csv('empathy-mental-health/dataset/train_output.csv')\n",
    "train_df_short = pd.read_csv('transformer models/datasets/red/train_df_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdaf0454-fecc-499a-8141-d8ba338d49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ER_IP_EX(convs_df, sl_ori):\n",
    "    '''\n",
    "    Add the columns of ER(emotional reaction), IP(interpretation), EX(exploration) and their rationale masks\n",
    "    to the original dataframe.\n",
    "    '''\n",
    "    convs, sl = convs_df.copy(), sl_ori.copy()\n",
    "    sl.rename({'response_post': 'text'}, axis = 1, inplace = True)\n",
    "\n",
    "    feat_list_to_keep = ['text', 'ER_label', 'ER_rationale_mask', 'IP_label', 'IP_rationale_mask', 'EX_label', 'EX_rationale_mask']\n",
    "    convs_masked = pd.merge(convs, sl[feat_list_to_keep], how = 'left', on = 'text')\n",
    "    \n",
    "    # fill in the missing value\n",
    "    # for comm level just fill 0; for masks fill the list with length as the text's\n",
    "    convs_masked['ER_label'].fillna(0, inplace = True)\n",
    "    convs_masked['IP_label'].fillna(0, inplace = True)\n",
    "    convs_masked['EX_label'].fillna(0, inplace = True)\n",
    "\n",
    "    for row in convs_masked.itertuples():\n",
    "\n",
    "        if pd.isna(row.ER_rationale_mask):\n",
    "            convs_masked.loc[row.Index, 'ER_rationale_mask'] = str([1] * len(row.text.split()))\n",
    "        \n",
    "        if pd.isna(row.IP_rationale_mask):\n",
    "            convs_masked.loc[row.Index, 'IP_rationale_mask'] = str([1] * len(row.text.split()))\n",
    "            \n",
    "        if pd.isna(row.EX_rationale_mask):\n",
    "            convs_masked.loc[row.Index, 'EX_rationale_mask'] = str([1] * len(row.text.split()))\n",
    "            \n",
    "    \n",
    "    return convs_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66d582-f1fa-4e5f-b986-8c2d095c77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update by adding the columns\n",
    "train_df_masked = add_ER_IP_EX(train_df_short, train_output)\n",
    "\n",
    "train_df_masked.to_csv('transformer models/datasets/red/train_df_masked.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a055a68-2b69-41ba-98e9-fb7b34c3adb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3169: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post title</th>\n",
       "      <th>author</th>\n",
       "      <th>dialog turn</th>\n",
       "      <th>text</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotion prediction</th>\n",
       "      <th>ER_label</th>\n",
       "      <th>ER_rationale_mask</th>\n",
       "      <th>IP_label</th>\n",
       "      <th>IP_rationale_mask</th>\n",
       "      <th>EX_label</th>\n",
       "      <th>EX_rationale_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>I've tried everything, but it's back.</td>\n",
       "      <td>speaker</td>\n",
       "      <td>1</td>\n",
       "      <td>It got worse and worse. I know they love me bu...</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>positive</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>I've tried everything, but it's back.</td>\n",
       "      <td>listener_1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hey you seem like a really sweet and nice pers...</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>positive</td>\n",
       "      <td>questioning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>depression</td>\n",
       "      <td>List of strange things I find depressing- Anyo...</td>\n",
       "      <td>speaker</td>\n",
       "      <td>1</td>\n",
       "      <td>* Sundays  * Yellow sunlight * Homework * Leav...</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>positive</td>\n",
       "      <td>lonely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>depression</td>\n",
       "      <td>List of strange things I find depressing- Anyo...</td>\n",
       "      <td>listener_1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.rotten fruit 2.my messy hair 3.children 4.fa...</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>negative</td>\n",
       "      <td>annoyed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>depression</td>\n",
       "      <td>Fuck me</td>\n",
       "      <td>speaker</td>\n",
       "      <td>1</td>\n",
       "      <td>I want to fucking die</td>\n",
       "      <td>-0.5984</td>\n",
       "      <td>negative</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011611</th>\n",
       "      <td>1494877</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>Childhood Abuse Survivor turned Trauma Informe...</td>\n",
       "      <td>listener_1</td>\n",
       "      <td>2</td>\n",
       "      <td>Thankyou for this. For sharing your personal e...</td>\n",
       "      <td>0.4753</td>\n",
       "      <td>positive</td>\n",
       "      <td>grateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011612</th>\n",
       "      <td>1494877</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>Childhood Abuse Survivor turned Trauma Informe...</td>\n",
       "      <td>speaker</td>\n",
       "      <td>3</td>\n",
       "      <td>It is my absolute honour and privilege to be a...</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>positive</td>\n",
       "      <td>grateful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011613</th>\n",
       "      <td>1494880</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>My team and I made this simple chatbot that he...</td>\n",
       "      <td>speaker</td>\n",
       "      <td>1</td>\n",
       "      <td>My team and I made this simple chatbot that he...</td>\n",
       "      <td>0.9117</td>\n",
       "      <td>positive</td>\n",
       "      <td>confident</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011614</th>\n",
       "      <td>1494880</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>My team and I made this simple chatbot that he...</td>\n",
       "      <td>listener_1</td>\n",
       "      <td>2</td>\n",
       "      <td>Thanks for this</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>positive</td>\n",
       "      <td>acknowledging</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011615</th>\n",
       "      <td>1494880</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>My team and I made this simple chatbot that he...</td>\n",
       "      <td>speaker</td>\n",
       "      <td>3</td>\n",
       "      <td>you're welcome</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>positive</td>\n",
       "      <td>sympathizing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011616 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         conversation id            subreddit  \\\n",
       "0                      1           depression   \n",
       "1                      1           depression   \n",
       "2                      4           depression   \n",
       "3                      4           depression   \n",
       "4                      7           depression   \n",
       "...                  ...                  ...   \n",
       "1011611          1494877  MentalHealthSupport   \n",
       "1011612          1494877  MentalHealthSupport   \n",
       "1011613          1494880  MentalHealthSupport   \n",
       "1011614          1494880  MentalHealthSupport   \n",
       "1011615          1494880  MentalHealthSupport   \n",
       "\n",
       "                                                post title      author  \\\n",
       "0                   I've tried everything, but it's back.      speaker   \n",
       "1                   I've tried everything, but it's back.   listener_1   \n",
       "2        List of strange things I find depressing- Anyo...     speaker   \n",
       "3        List of strange things I find depressing- Anyo...  listener_1   \n",
       "4                                                  Fuck me     speaker   \n",
       "...                                                    ...         ...   \n",
       "1011611  Childhood Abuse Survivor turned Trauma Informe...  listener_1   \n",
       "1011612  Childhood Abuse Survivor turned Trauma Informe...     speaker   \n",
       "1011613  My team and I made this simple chatbot that he...     speaker   \n",
       "1011614  My team and I made this simple chatbot that he...  listener_1   \n",
       "1011615  My team and I made this simple chatbot that he...     speaker   \n",
       "\n",
       "         dialog turn                                               text  \\\n",
       "0                  1  It got worse and worse. I know they love me bu...   \n",
       "1                  2  Hey you seem like a really sweet and nice pers...   \n",
       "2                  1  * Sundays  * Yellow sunlight * Homework * Leav...   \n",
       "3                  2  1.rotten fruit 2.my messy hair 3.children 4.fa...   \n",
       "4                  1                              I want to fucking die   \n",
       "...              ...                                                ...   \n",
       "1011611            2  Thankyou for this. For sharing your personal e...   \n",
       "1011612            3  It is my absolute honour and privilege to be a...   \n",
       "1011613            1  My team and I made this simple chatbot that he...   \n",
       "1011614            2                                    Thanks for this   \n",
       "1011615            3                                     you're welcome   \n",
       "\n",
       "        compound sentiment emotion prediction  ER_label  \\\n",
       "0         0.9948  positive            ashamed       0.0   \n",
       "1         0.8341  positive        questioning       1.0   \n",
       "2         0.1786  positive             lonely       0.0   \n",
       "3        -0.3612  negative            annoyed       0.0   \n",
       "4        -0.5984  negative            ashamed       0.0   \n",
       "...          ...       ...                ...       ...   \n",
       "1011611   0.4753  positive           grateful       1.0   \n",
       "1011612   0.9098  positive           grateful       0.0   \n",
       "1011613   0.9117  positive          confident       0.0   \n",
       "1011614   0.4404  positive      acknowledging       0.0   \n",
       "1011615   0.4588  positive       sympathizing       1.0   \n",
       "\n",
       "                                         ER_rationale_mask  IP_label  \\\n",
       "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0.0   \n",
       "1        [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...       0.0   \n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0.0   \n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       2.0   \n",
       "4                                          [1, 1, 1, 1, 1]       0.0   \n",
       "...                                                    ...       ...   \n",
       "1011611  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0.0   \n",
       "1011612               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]       0.0   \n",
       "1011613  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0.0   \n",
       "1011614                                          [1, 1, 1]       0.0   \n",
       "1011615                                          [1, 1, 1]       0.0   \n",
       "\n",
       "                                         IP_rationale_mask  EX_label  \\\n",
       "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0.0   \n",
       "1        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...       2.0   \n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0.0   \n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0.0   \n",
       "4                                          [1, 1, 1, 1, 1]       0.0   \n",
       "...                                                    ...       ...   \n",
       "1011611  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0.0   \n",
       "1011612               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]       0.0   \n",
       "1011613  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0.0   \n",
       "1011614                                          [1, 1, 1]       0.0   \n",
       "1011615                                          [1, 1, 1]       0.0   \n",
       "\n",
       "                                         EX_rationale_mask  \n",
       "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4                                          [1, 1, 1, 1, 1]  \n",
       "...                                                    ...  \n",
       "1011611  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1011612               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "1011613  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1011614                                          [1, 1, 1]  \n",
       "1011615                                          [1, 1, 1]  \n",
       "\n",
       "[1011616 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_masked = pd.read_csv('datasets/red/train_df_masked.csv')\n",
    "\n",
    "train_df_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f13b8ca-da92-4b33-9eed-636523f63f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_masked = train_df_masked.drop_duplicates()\n",
    "train_df_masked.to_csv('datasets/red/train_df_masked.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e82db-776f-49ce-a24f-a80450da530f",
   "metadata": {},
   "source": [
    "---------\n",
    "Check if testing set works suitably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97401ede-b3e9-42cc-bafd-43e42507079f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is 50265.\n",
      "Reading encoded data from \"datasets/red/train/encoded.txt\"...\n",
      "Reading emotions from \"datasets/red/train/uttr_emots.npy\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 525657/525657 [00:33<00:00, 15584.32it/s]\n",
      "2021-11-24 20:29:18.029337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-24 20:29:18.209389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1\n",
      "coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\n",
      "2021-11-24 20:29:18.210733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1\n",
      "coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\n",
      "2021-11-24 20:29:18.212072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: \n",
      "pciBusID: 0000:84:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1\n",
      "coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\n",
      "2021-11-24 20:29:18.213451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: \n",
      "pciBusID: 0000:85:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1\n",
      "coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\n",
      "2021-11-24 20:29:18.213480: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-24 20:29:18.215213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-24 20:29:18.216878: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-24 20:29:18.217186: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-24 20:29:18.218970: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-24 20:29:18.219896: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-24 20:29:18.223746: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-24 20:29:18.234230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2021-11-24 20:29:18.234936: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-24 20:29:18.246084: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499780000 Hz\n",
      "2021-11-24 20:29:18.249530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fd06c10090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-24 20:29:18.249564: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-24 20:29:19.285930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fd147967e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-24 20:29:19.285969: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2021-11-24 20:29:19.285978: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2021-11-24 20:29:19.285986: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2021-11-24 20:29:19.285993: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2021-11-24 20:29:19.291832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1\n",
      "coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\n",
      "2021-11-24 20:29:19.292445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1\n",
      "coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\n",
      "2021-11-24 20:29:19.293071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: \n",
      "pciBusID: 0000:84:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1\n",
      "coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\n",
      "2021-11-24 20:29:19.293672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: \n",
      "pciBusID: 0000:85:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1\n",
      "coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\n",
      "2021-11-24 20:29:19.293750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-24 20:29:19.293810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-24 20:29:19.293852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-24 20:29:19.293892: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-24 20:29:19.293932: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-24 20:29:19.293971: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-24 20:29:19.294012: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-24 20:29:19.298506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2021-11-24 20:29:19.298583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-24 20:29:20.723016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-24 20:29:20.723053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 2 3 \n",
      "2021-11-24 20:29:20.723060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N Y N N \n",
      "2021-11-24 20:29:20.723064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   Y N N N \n",
      "2021-11-24 20:29:20.723067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N N N Y \n",
      "2021-11-24 20:29:20.723071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N N Y N \n",
      "2021-11-24 20:29:20.725118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-11-24 20:29:20.726080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11228 MB memory) -> physical GPU (device: 1, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-11-24 20:29:20.726901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 11228 MB memory) -> physical GPU (device: 2, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:84:00.0, compute capability: 6.1)\n",
      "2021-11-24 20:29:20.727780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 11228 MB memory) -> physical GPU (device: 3, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:85:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading encoded data from \"datasets/red/valid/encoded.txt\"...\n",
      "Reading emotions from \"datasets/red/valid/uttr_emots.npy\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 65714/65714 [00:04<00:00, 15664.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading encoded data from \"datasets/red/test/encoded.txt\"...\n",
      "Reading emotions from \"datasets/red/test/uttr_emots.npy\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 13745/13745 [00:00<00:00, 16144.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import RobertaTokenizer\n",
    "from datasets import *\n",
    "from math import ceil\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "data_path = 'datasets/red'\n",
    "batch_size = 512\n",
    "buffer_size = 100000\n",
    "max_length = 100\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(tokenizer, data_path, buffer_size, batch_size, max_length, contain_comm = False, contain_mask = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c57f9c86-7758-490d-91fc-e86dddc4a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    for (batch, inputs) in enumerate(train_dataset):\n",
    "        inp, inp_seg, inp_emot, tar_inp, tar_real, tar_seg, tar_emot = inputs\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a940d0c-0cdd-4660-bfd6-152cf1d065e8",
   "metadata": {},
   "source": [
    "why create_test_dataset fail to capture speaker/listener?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63eb0c79-d354-45f5-9b89-bbad99e43e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading encoded data from \"datasets/red+_mask/train/encoded.txt\"...\n",
      "Reading emotions from \"datasets/red+_mask/train/uttr_emots.npy\"...\n",
      "Reading emotions from \"datasets/red+_mask/train/uttr_masks.npy\"...\n"
     ]
    }
   ],
   "source": [
    "read_path = 'datasets/red+_mask/train' # this dataset has no comm files\n",
    "max_length = 100\n",
    "\n",
    "encoded_path = join(read_path, 'encoded.txt')\n",
    "f = open(encoded_path, 'r', encoding = 'utf-8')\n",
    "print('Reading encoded data from \\\"{}\\\"...'.format(encoded_path))\n",
    "lines = f.read().splitlines()\n",
    "\n",
    "uttr_emots_path = join(read_path, 'uttr_emots.npy')\n",
    "# uttr_comms_path = join(read_path, 'uttr_comms.npy')\n",
    "uttr_masks_path = join(read_path, 'uttr_masks.npy')\n",
    "print('Reading emotions from \\\"{}\\\"...'.format(uttr_emots_path))\n",
    "# print('Reading emotions from \\\"{}\\\"...'.format(uttr_comms_path))\n",
    "print('Reading emotions from \\\"{}\\\"...'.format(uttr_masks_path))\n",
    "uttr_emots = np.load(uttr_emots_path)\n",
    "# uttr_comms = np.load(uttr_comms_path)\n",
    "uttr_masks = np.load(uttr_masks_path, allow_pickle = True)\n",
    "#uttr_emots = np.argsort(uttr_emots, axis = 1)\n",
    "\n",
    "# RoBERTa uses 1 as the padding value\n",
    "inputs = np.ones((len(lines), max_length), dtype = np.int32)\n",
    "input_segments = np.ones((len(lines), max_length), dtype = np.int32)\n",
    "input_emots = np.zeros((len(lines), max_length), dtype = np.int32)\n",
    "# input_comms = np.zeros((len(lines), max_length), dtype = np.int32)\n",
    "targets_i = np.ones((len(lines), max_length), dtype = np.int32)\n",
    "targets_r = np.ones((len(lines), max_length), dtype = np.int32)\n",
    "target_segments = np.ones((len(lines), max_length), dtype = np.int32)\n",
    "target_emots = np.zeros(len(lines), dtype = np.int32)\n",
    "targets_mask = np.zeros((len(lines), max_length), dtype = np.int32)\n",
    "# target_comms = np.zeros(len(lines), dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06b4651c-fc93-4835-a604-3040edce1810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 241247/241247 [00:17<00:00, 13649.56it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for i, line in tqdm(enumerate(lines), total = len(lines)):\n",
    "    # 0,8976,2156,2085,52,32,11,761,9,10,910,1182,479,2 0,0,0,0,0,0,0,0,0,0,0,0,0,0 0,8976,2156,38,619,101,38,697,10,1256,455,301,479,38,1266,2156,38,128,119,1819,117,810,326,4218,479,256,119,479,2   1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1   0,1\n",
    "    inp_str, inp_seg_str, tar_str, tar_seg_str, idx_str = line.split('\\t')\n",
    "    j, k = [int(s) for s in idx_str.split(',')]\n",
    "\n",
    "    inp_ids = [int(s) for s in inp_str.split(',')]\n",
    "    inp_seg_ids = [int(s) for s in inp_seg_str.split(',')]\n",
    "    tar_ids = [int(s) for s in tar_str.split(',')]\n",
    "    tar_seg_ids = [int(s) for s in tar_seg_str.split(',')]\n",
    "\n",
    "\n",
    "    seg_id = 0\n",
    "    for x in range(len(inp_seg_ids)):\n",
    "        if inp_seg_ids[x] != seg_id:\n",
    "            j += 1\n",
    "            seg_id = inp_seg_ids[x]\n",
    "        #input_emots[i,x] = uttr_emots[j,-1]\n",
    "        input_emots[i,x] = uttr_emots[j] # add the current emotion label on the speaker segment indices in the input_emots array (2D with shape as (# of example, max_length))\n",
    "    #target_emots[i] = uttr_emots[k,-1]\n",
    "    target_emots[i] = uttr_emots[k] # simply add the emotion label to the target_emots array (1D with shape as (# of example, ))\n",
    "    # target_comms[i] = uttr_comms[k]\n",
    "    \n",
    "    inputs[i,:len(inp_ids)] = inp_ids\n",
    "    input_segments[i,:len(inp_seg_ids)] = inp_seg_ids\n",
    "    targets_i[i,:len(tar_ids)-1] = tar_ids[:-1]\n",
    "    targets_r[i,:len(tar_ids)-1] = tar_ids[1:]\n",
    "    target_segments[i,:len(tar_seg_ids)-1] = tar_seg_ids[:-1]\n",
    "    \n",
    "    if len(uttr_masks[k]) > max_length:\n",
    "        targets_mask[i,:max_length] = uttr_masks[k][:max_length]\n",
    "    else:\n",
    "        targets_mask[i,:len(uttr_masks[k])] = uttr_masks[k]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e151dfe2-ee78-4c28-b35f-ba6ff9fc68fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(targets_mask > 1) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42f900-7661-4e98-89af-870b76af01e5",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "check the new version (adding comm level) work suitably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2a6889-04dd-4e3a-9374-c586526cdf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 0/73629 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading encoded data from \"datasets/red+/test/encoded.txt\"...\n",
      "Reading emotions from \"datasets/red+/test/uttr_emots.npy\"...\n",
      "Reading emotions from \"datasets/red+/test/uttr_comms.npy\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 73629/73629 [00:05<00:00, 12595.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((<TensorSliceDataset shapes: (100,), types: tf.int32>,\n",
       "  <TensorSliceDataset shapes: (100,), types: tf.int32>,\n",
       "  <TensorSliceDataset shapes: (100,), types: tf.int32>,\n",
       "  <TensorSliceDataset shapes: (100,), types: tf.int32>,\n",
       "  <TensorSliceDataset shapes: (100,), types: tf.int32>,\n",
       "  <TensorSliceDataset shapes: (100,), types: tf.int32>,\n",
       "  <TensorSliceDataset shapes: (100,), types: tf.int32>,\n",
       "  <TensorSliceDataset shapes: (), types: tf.int32>,\n",
       "  <TensorSliceDataset shapes: (), types: tf.int32>),\n",
       " 73629)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to adjust the create_dataset in datasets.py to contain comm level\n",
    "read_path = 'datasets/red+/test'\n",
    "max_length = 100\n",
    "\n",
    "\n",
    "create_dataset(read_path, max_length, contain_comm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59dee0-89e7-4153-885a-bafe5d5274db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
